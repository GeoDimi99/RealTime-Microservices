Project Context for: RealTime-Microservices
==================================================

=== DIRECTORY STRUCTURE ===
RealTime-Microservices/
    README.md
    docker-compose.yml
    docs/
        generate_context.py
    common/
        CMakeLists.txt
        include/
            task.h
            task_ipc.h
            logger.h
        src/
            task_ipc.c
            logger.c
    services/
        execution-manager/
            CMakeLists.txt
            Dockerfile
            include/
                jsmn.h
                redis_reader.h
            src/
                redis_reader.c
                main.c
        task-service/
            CMakeLists.txt
            Dockerfile
            include/
                task_config.h.in
                task_service.h
                task_entry.h
            src/
                main.c
        deploy-manager/
            Dockerfile
            pyproject.toml
            src/
                __init__.py
                logger.py
                exceptions.py
                main.py
                database/
                    __init__.py
                    redis_loader.py
                deploy/
                    runner.py
                    __init__.py
                    materializer.py
                    builder.py
                manifest/
                    manifest_fetcher.py
                    __init__.py
                    parser.py
                domain/
                    task.py
                    __init__.py
                    schedule.py

=== FILE CONTENTS ===

--- START FILE: README.md ---
# RealTime Microservices

--- END FILE: README.md ---

--- START FILE: docker-compose.yml ---

services:
  
  redis:
    image: "redis:8.4"
    cpuset: "1"
    container_name: redis
    ports:
      - "6379:6379"

  deploy-manager:
    build:
      context: . 
      dockerfile: ./services/deploy-manager/Dockerfile
    cpuset: "1"
    container_name: deploy-manager
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - redis
    

  #exection-manager:
    #build:
      #context: . 
      #dockerfile: ./services/execution-manager/Dockerfile
    #cpuset: "1"
    #container_name: execution-manager
    #depends_on:
     #- redis
     #- deploy-manager
  


--- END FILE: docker-compose.yml ---

--- START FILE: common/CMakeLists.txt ---
cmake_minimum_required(VERSION 3.20)
project(common C)

# Optional: create a static library for common code
add_library(common STATIC)

# Include directories for headers
target_include_directories(common PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
)

# Add source files if you have .c in common/src
target_sources(common PRIVATE src/logger.c src/task_ipc.c)

# If you only have headers, the library can be empty
--- END FILE: common/CMakeLists.txt ---

--- START FILE: common/include/task.h ---
#ifndef TASK_H
#define TASK_H

#include <stdint.h>

#define TASK_NAME_MAX        64
#define TASK_JSON_IN_MAX     512
#define TASK_JSON_OUT_MAX    512

#define TASK_PRIORITY_MIN 1
#define TASK_PRIORITY_MAX 99

/* Scheduling Policies */
typedef enum {
    SCHED_POLICY_OTHER = 0,
    SCHED_POLICY_FIFO  = 1,
    SCHED_POLICY_RR    = 2
} sched_policy_t;

/* Task struct */
typedef struct {
    char task_name[TASK_NAME_MAX];
    sched_policy_t policy;
    uint8_t priority;  /* 1â€“99 */
    char input[TASK_JSON_IN_MAX];
    char output[TASK_JSON_OUT_MAX];
} task_t;

#endif /* TASK_H */

--- END FILE: common/include/task.h ---

--- START FILE: common/include/task_ipc.h ---
#ifndef TASK_IPC_H
#define TASK_IPC_H

#include <stdint.h>
#include <mqueue.h>
#include "task.h"

/* Queue names */
#define QUEUE_NAME_EM   "/execution_manager"

/* Message types */
typedef enum {
    MSG_TASK_REQUEST = 1,
    MSG_TASK_ACK,
    MSG_GET_STATUS,
    MSG_TASK_STATUS,
    MSG_GET_RESULTS,
    MSG_TASK_RESULT
} msg_type_t;

/* ACK status */
typedef enum {
    ACK_OK = 0,
    ACK_ERROR = 1
} ack_status_t;

/* Task-service states */
typedef enum {
    TS_IDLE = 0,
    TS_RUNNING,
    TS_COMPLETED
} task_service_state_t;

/* IPC message */
typedef struct {
    msg_type_t type;
    uint32_t   task_id;

    union {
        task_t task;                  /* For TASK_REQUEST */
        ack_status_t ack;              /* For TASK_ACK */
        task_service_state_t status;   /* For STATUS */
        char result[TASK_JSON_OUT_MAX];/* For TASK_RESULT */
    } data;
} ipc_msg_t;

/* POSIX MQ helpers */
mqd_t create_queue(const char *name, int flags);
int send_message(mqd_t qd, const ipc_msg_t *msg);
int receive_message(mqd_t qd, ipc_msg_t *msg);

#endif /* TASK_IPC_H */

--- END FILE: common/include/task_ipc.h ---

--- START FILE: common/include/logger.h ---
#ifndef LOGGER_H
#define LOGGER_H

#include <stdio.h>

typedef enum {
    LOG_INFO,
    LOG_WARN,
    LOG_ERROR
} log_level_t;

/* Log a formatted message */
void log_message(log_level_t level, const char *source, const char *fmt, ...);

#endif /* LOGGER_H */

--- END FILE: common/include/logger.h ---

--- START FILE: common/src/task_ipc.c ---
#include "task_ipc.h"
#include <fcntl.h>
#include <stdio.h>
#include <errno.h>
#include <string.h>
#include <stdlib.h>

/* Create/open queue with flags (O_RDONLY, O_WRONLY, O_NONBLOCK) */
mqd_t create_queue(const char *name, int flags)
{
    struct mq_attr attr = {
        .mq_flags   = (flags & O_NONBLOCK) ? O_NONBLOCK : 0,
        .mq_maxmsg  = 10,
        .mq_msgsize = sizeof(ipc_msg_t),
        .mq_curmsgs = 0
    };

    mqd_t qd = mq_open(name, flags | O_CREAT, 0666, &attr);
    if (qd == (mqd_t)-1) {
        perror("mq_open");
        exit(EXIT_FAILURE);
    }
    return qd;
}

/* Send a message */
int send_message(mqd_t qd, const ipc_msg_t *msg)
{
    return mq_send(qd, (const char *)msg, sizeof(*msg), 0);
}

/* Receive a message (blocking or non-blocking depending on queue flags) */
int receive_message(mqd_t qd, ipc_msg_t *msg)
{
    ssize_t ret = mq_receive(qd, (char *)msg, sizeof(*msg), NULL);
    if (ret == -1) {
        if (errno == EAGAIN) {
            return 0; /* no message available for non-blocking */
        }
        perror("mq_receive");
        return -1;
    }
    return 1; /* message received */
}

--- END FILE: common/src/task_ipc.c ---

--- START FILE: common/src/logger.c ---
#include "logger.h"
#include <time.h>
#include <stdarg.h>

/* Get timestamp in "YYYY-MM-DD HH:MM:SS,ms" format */
static void get_timestamp(char *buffer, size_t len) {
    struct timespec ts;
    struct tm tm_info;

    clock_gettime(CLOCK_REALTIME, &ts);
    localtime_r(&ts.tv_sec, &tm_info);

    int ms = ts.tv_nsec / 1000000;

    snprintf(buffer, len, "%04d-%02d-%02d %02d:%02d:%02d,%03d",
             tm_info.tm_year + 1900,
             tm_info.tm_mon + 1,
             tm_info.tm_mday,
             tm_info.tm_hour,
             tm_info.tm_min,
             tm_info.tm_sec,
             ms);
}

void log_message(log_level_t level, const char *source, const char *fmt, ...) {
    static const char *level_str[] = {"INFO", "WARN", "ERROR"};

    char timestamp[32];
    get_timestamp(timestamp, sizeof(timestamp));

    // Build formatted message
    va_list args;
    va_start(args, fmt);

    printf("%s [%s] %s: ", timestamp, level_str[level], source);
    vprintf(fmt, args);
    printf("\n");

    va_end(args);

    // Optionally flush immediately for RT logging
    fflush(stdout);
}

--- END FILE: common/src/logger.c ---

--- START FILE: services/execution-manager/CMakeLists.txt ---
cmake_minimum_required(VERSION 3.20)
project(task_service C)

set(CMAKE_C_STANDARD 99)
set(CMAKE_C_STANDARD_REQUIRED ON)
set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -Wall -Wextra -O2")

# Include directories
include_directories(${CMAKE_CURRENT_SOURCE_DIR}/include)
include_directories(${CMAKE_SOURCE_DIR}/../common/include)

# Add executable
add_executable(execution-manager
    src/main.c
    src/redis_reader.c
    ../common/src/logger.c  # directly add logger.c to build
    ../common/src/task_ipc.c
)

# Threads
find_package(Threads REQUIRED)
target_link_libraries(execution-manager PRIVATE Threads::Threads hiredis)

--- END FILE: services/execution-manager/CMakeLists.txt ---

--- START FILE: services/execution-manager/Dockerfile ---
FROM ubuntu:24.04

# Install build tools
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        build-essential \
        cmake \
        libhiredis-dev && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy common headers
COPY common/ ./common/

# Copy execution-manager source
COPY services/execution-manager/ ./execution-manager/

WORKDIR /app/execution-manager

# Configure and build
RUN cmake -S . -B build
RUN cmake --build build

ENTRYPOINT ["./build/execution-manager"]

--- END FILE: services/execution-manager/Dockerfile ---

--- START FILE: services/execution-manager/include/jsmn.h ---
/*
 * MIT License
 *
 * Copyright (c) 2010 Serge Zaitsev
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
#ifndef JSMN_H
#define JSMN_H

#include <stddef.h>

#ifdef __cplusplus
extern "C" {
#endif

#ifdef JSMN_STATIC
#define JSMN_API static
#else
#define JSMN_API extern
#endif

/**
 * JSON type identifier. Basic types are:
 * 	o Object
 * 	o Array
 * 	o String
 * 	o Other primitive: number, boolean (true/false) or null
 */
typedef enum {
  JSMN_UNDEFINED = 0,
  JSMN_OBJECT = 1 << 0,
  JSMN_ARRAY = 1 << 1,
  JSMN_STRING = 1 << 2,
  JSMN_PRIMITIVE = 1 << 3
} jsmntype_t;

enum jsmnerr {
  /* Not enough tokens were provided */
  JSMN_ERROR_NOMEM = -1,
  /* Invalid character inside JSON string */
  JSMN_ERROR_INVAL = -2,
  /* The string is not a full JSON packet, more bytes expected */
  JSMN_ERROR_PART = -3
};

/**
 * JSON token description.
 * type		type (object, array, string etc.)
 * start	start position in JSON data string
 * end		end position in JSON data string
 */
typedef struct jsmntok {
  jsmntype_t type;
  int start;
  int end;
  int size;
#ifdef JSMN_PARENT_LINKS
  int parent;
#endif
} jsmntok_t;

/**
 * JSON parser. Contains an array of token blocks available. Also stores
 * the string being parsed now and current position in that string.
 */
typedef struct jsmn_parser {
  unsigned int pos;     /* offset in the JSON string */
  unsigned int toknext; /* next token to allocate */
  int toksuper;         /* superior token node, e.g. parent object or array */
} jsmn_parser;

/**
 * Create JSON parser over an array of tokens
 */
JSMN_API void jsmn_init(jsmn_parser *parser);

/**
 * Run JSON parser. It parses a JSON data string into and array of tokens, each
 * describing
 * a single JSON object.
 */
JSMN_API int jsmn_parse(jsmn_parser *parser, const char *js, const size_t len,
                        jsmntok_t *tokens, const unsigned int num_tokens);

#ifndef JSMN_HEADER
/**
 * Allocates a fresh unused token from the token pool.
 */
static jsmntok_t *jsmn_alloc_token(jsmn_parser *parser, jsmntok_t *tokens,
                                   const size_t num_tokens) {
  jsmntok_t *tok;
  if (parser->toknext >= num_tokens) {
    return NULL;
  }
  tok = &tokens[parser->toknext++];
  tok->start = tok->end = -1;
  tok->size = 0;
#ifdef JSMN_PARENT_LINKS
  tok->parent = -1;
#endif
  return tok;
}

/**
 * Fills token type and boundaries.
 */
static void jsmn_fill_token(jsmntok_t *token, const jsmntype_t type,
                            const int start, const int end) {
  token->type = type;
  token->start = start;
  token->end = end;
  token->size = 0;
}

/**
 * Fills next available token with JSON primitive.
 */
static int jsmn_parse_primitive(jsmn_parser *parser, const char *js,
                                const size_t len, jsmntok_t *tokens,
                                const size_t num_tokens) {
  jsmntok_t *token;
  int start;

  start = parser->pos;

  for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
    switch (js[parser->pos]) {
#ifndef JSMN_STRICT
    /* In strict mode primitive must be followed by "," or "}" or "]" */
    case ':':
#endif
    case '\t':
    case '\r':
    case '\n':
    case ' ':
    case ',':
    case ']':
    case '}':
      goto found;
    default:
                   /* to quiet a warning from gcc*/
      break;
    }
    if (js[parser->pos] < 32 || js[parser->pos] >= 127) {
      parser->pos = start;
      return JSMN_ERROR_INVAL;
    }
  }
#ifdef JSMN_STRICT
  /* In strict mode primitive must be followed by a comma/object/array */
  parser->pos = start;
  return JSMN_ERROR_PART;
#endif

found:
  if (tokens == NULL) {
    parser->pos--;
    return 0;
  }
  token = jsmn_alloc_token(parser, tokens, num_tokens);
  if (token == NULL) {
    parser->pos = start;
    return JSMN_ERROR_NOMEM;
  }
  jsmn_fill_token(token, JSMN_PRIMITIVE, start, parser->pos);
#ifdef JSMN_PARENT_LINKS
  token->parent = parser->toksuper;
#endif
  parser->pos--;
  return 0;
}

/**
 * Fills next token with JSON string.
 */
static int jsmn_parse_string(jsmn_parser *parser, const char *js,
                             const size_t len, jsmntok_t *tokens,
                             const size_t num_tokens) {
  jsmntok_t *token;

  int start = parser->pos;
  
  /* Skip starting quote */
  parser->pos++;
  
  for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
    char c = js[parser->pos];

    /* Quote: end of string */
    if (c == '\"') {
      if (tokens == NULL) {
        return 0;
      }
      token = jsmn_alloc_token(parser, tokens, num_tokens);
      if (token == NULL) {
        parser->pos = start;
        return JSMN_ERROR_NOMEM;
      }
      jsmn_fill_token(token, JSMN_STRING, start + 1, parser->pos);
#ifdef JSMN_PARENT_LINKS
      token->parent = parser->toksuper;
#endif
      return 0;
    }

    /* Backslash: Quoted symbol expected */
    if (c == '\\' && parser->pos + 1 < len) {
      int i;
      parser->pos++;
      switch (js[parser->pos]) {
      /* Allowed escaped symbols */
      case '\"':
      case '/':
      case '\\':
      case 'b':
      case 'f':
      case 'r':
      case 'n':
      case 't':
        break;
      /* Allows escaped symbol \uXXXX */
      case 'u':
        parser->pos++;
        for (i = 0; i < 4 && parser->pos < len && js[parser->pos] != '\0';
             i++) {
          /* If it isn't a hex character we have an error */
          if (!((js[parser->pos] >= 48 && js[parser->pos] <= 57) ||   /* 0-9 */
                (js[parser->pos] >= 65 && js[parser->pos] <= 70) ||   /* A-F */
                (js[parser->pos] >= 97 && js[parser->pos] <= 102))) { /* a-f */
            parser->pos = start;
            return JSMN_ERROR_INVAL;
          }
          parser->pos++;
        }
        parser->pos--;
        break;
      /* Unexpected symbol */
      default:
        parser->pos = start;
        return JSMN_ERROR_INVAL;
      }
    }
  }
  parser->pos = start;
  return JSMN_ERROR_PART;
}

/**
 * Parse JSON string and fill tokens.
 */
JSMN_API int jsmn_parse(jsmn_parser *parser, const char *js, const size_t len,
                        jsmntok_t *tokens, const unsigned int num_tokens) {
  int r;
  int i;
  jsmntok_t *token;
  int count = parser->toknext;

  for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
    char c;
    jsmntype_t type;

    c = js[parser->pos];
    switch (c) {
    case '{':
    case '[':
      count++;
      if (tokens == NULL) {
        break;
      }
      token = jsmn_alloc_token(parser, tokens, num_tokens);
      if (token == NULL) {
        return JSMN_ERROR_NOMEM;
      }
      if (parser->toksuper != -1) {
        jsmntok_t *t = &tokens[parser->toksuper];
#ifdef JSMN_STRICT
        /* In strict mode an object or array can't become a key */
        if (t->type == JSMN_OBJECT) {
          return JSMN_ERROR_INVAL;
        }
#endif
        t->size++;
#ifdef JSMN_PARENT_LINKS
        token->parent = parser->toksuper;
#endif
      }
      token->type = (c == '{' ? JSMN_OBJECT : JSMN_ARRAY);
      token->start = parser->pos;
      parser->toksuper = parser->toknext - 1;
      break;
    case '}':
    case ']':
      if (tokens == NULL) {
        break;
      }
      type = (c == '}' ? JSMN_OBJECT : JSMN_ARRAY);
#ifdef JSMN_PARENT_LINKS
      if (parser->toknext < 1) {
        return JSMN_ERROR_INVAL;
      }
      token = &tokens[parser->toknext - 1];
      for (;;) {
        if (token->start != -1 && token->end == -1) {
          if (token->type != type) {
            return JSMN_ERROR_INVAL;
          }
          token->end = parser->pos + 1;
          parser->toksuper = token->parent;
          break;
        }
        if (token->parent == -1) {
          if (token->type != type || parser->toksuper == -1) {
            return JSMN_ERROR_INVAL;
          }
          break;
        }
        token = &tokens[token->parent];
      }
#else
      for (i = parser->toknext - 1; i >= 0; i--) {
        token = &tokens[i];
        if (token->start != -1 && token->end == -1) {
          if (token->type != type) {
            return JSMN_ERROR_INVAL;
          }
          parser->toksuper = -1;
          token->end = parser->pos + 1;
          break;
        }
      }
      /* Error if unmatched closing bracket */
      if (i == -1) {
        return JSMN_ERROR_INVAL;
      }
      for (; i >= 0; i--) {
        token = &tokens[i];
        if (token->start != -1 && token->end == -1) {
          parser->toksuper = i;
          break;
        }
      }
#endif
      break;
    case '\"':
      r = jsmn_parse_string(parser, js, len, tokens, num_tokens);
      if (r < 0) {
        return r;
      }
      count++;
      if (parser->toksuper != -1 && tokens != NULL) {
        tokens[parser->toksuper].size++;
      }
      break;
    case '\t':
    case '\r':
    case '\n':
    case ' ':
      break;
    case ':':
      parser->toksuper = parser->toknext - 1;
      break;
    case ',':
      if (tokens != NULL && parser->toksuper != -1 &&
          tokens[parser->toksuper].type != JSMN_ARRAY &&
          tokens[parser->toksuper].type != JSMN_OBJECT) {
#ifdef JSMN_PARENT_LINKS
        parser->toksuper = tokens[parser->toksuper].parent;
#else
        for (i = parser->toknext - 1; i >= 0; i--) {
          if (tokens[i].type == JSMN_ARRAY || tokens[i].type == JSMN_OBJECT) {
            if (tokens[i].start != -1 && tokens[i].end == -1) {
              parser->toksuper = i;
              break;
            }
          }
        }
#endif
      }
      break;
#ifdef JSMN_STRICT
    /* In strict mode primitives are: numbers and booleans */
    case '-':
    case '0':
    case '1':
    case '2':
    case '3':
    case '4':
    case '5':
    case '6':
    case '7':
    case '8':
    case '9':
    case 't':
    case 'f':
    case 'n':
      /* And they must not be keys of the object */
      if (tokens != NULL && parser->toksuper != -1) {
        const jsmntok_t *t = &tokens[parser->toksuper];
        if (t->type == JSMN_OBJECT ||
            (t->type == JSMN_STRING && t->size != 0)) {
          return JSMN_ERROR_INVAL;
        }
      }
#else
    /* In non-strict mode every unquoted value is a primitive */
    default:
#endif
      r = jsmn_parse_primitive(parser, js, len, tokens, num_tokens);
      if (r < 0) {
        return r;
      }
      count++;
      if (parser->toksuper != -1 && tokens != NULL) {
        tokens[parser->toksuper].size++;
      }
      break;

#ifdef JSMN_STRICT
    /* Unexpected char in strict mode */
    default:
      return JSMN_ERROR_INVAL;
#endif
    }
  }

  if (tokens != NULL) {
    for (i = parser->toknext - 1; i >= 0; i--) {
      /* Unmatched opened object or array */
      if (tokens[i].start != -1 && tokens[i].end == -1) {
        return JSMN_ERROR_PART;
      }
    }
  }

  return count;
}

/**
 * Creates a new parser based over a given buffer with an array of tokens
 * available.
 */
JSMN_API void jsmn_init(jsmn_parser *parser) {
  parser->pos = 0;
  parser->toknext = 0;
  parser->toksuper = -1;
}

#endif /* JSMN_HEADER */

#ifdef __cplusplus
}
#endif

#endif /* JSMN_H */
--- END FILE: services/execution-manager/include/jsmn.h ---

--- START FILE: services/execution-manager/include/redis_reader.h ---
#ifndef REDIS_READER_H
#define REDIS_READER_H

#include <hiredis/hiredis.h>

#define MAX_TASKS     32
#define MAX_JSON_LEN  1024

typedef struct {
    char name[64];
    char policy[16];
    int  priority;
    char inputs[MAX_JSON_LEN];   // JSON string
    char outputs[MAX_JSON_LEN];  // JSON string
} task_t;

typedef struct {
    char name[64];
    char version[16];
    char description[128];
    int  num_tasks;
    task_t tasks[MAX_TASKS];
} schedule_t;

redisContext* redis_connect(const char *host, int port);
int redis_wait_for_schedule(redisContext *ctx);
int redis_read_schedule(redisContext *ctx, schedule_t *schedule);

#endif

--- END FILE: services/execution-manager/include/redis_reader.h ---

--- START FILE: services/execution-manager/src/redis_reader.c ---
#include "redis_reader.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>

/* ---------- Redis ---------- */

redisContext* redis_connect(const char *host, int port)
{
    redisContext *ctx = redisConnect(host, port);
    if (!ctx || ctx->err) {
        fprintf(stderr, "Redis connection error\n");
        exit(1);
    }
    return ctx;
}

int redis_wait_for_schedule(redisContext *ctx)
{
    while (1) {
        redisReply *r = redisCommand(ctx, "EXISTS schedule");
        if (r && r->integer == 1) {
            freeReplyObject(r);
            return 0;
        }
        if (r) freeReplyObject(r);
        sleep(1);
    }
}

/* ---------- Helpers ---------- */

static const char* hget(redisReply *r, const char *key)
{
    for (size_t i = 0; i < r->elements; i += 2) {
        if (strcmp(r->element[i]->str, key) == 0)
            return r->element[i + 1]->str;
    }
    return NULL;
}

/* ---------- Main Reader ---------- */

int redis_read_schedule(redisContext *ctx, schedule_t *sched)
{
    redisReply *r = redisCommand(ctx, "HGETALL schedule");
    if (!r || r->type != REDIS_REPLY_ARRAY) return -1;

    const char *v;

    if ((v = hget(r, "name")))
        strncpy(sched->name, v, sizeof(sched->name));

    if ((v = hget(r, "version")))
        strncpy(sched->version, v, sizeof(sched->version));

    if ((v = hget(r, "description")))
        strncpy(sched->description, v, sizeof(sched->description));

    if ((v = hget(r, "length")))
        sched->num_tasks = atoi(v);

    freeReplyObject(r);

    /* ---------- Tasks ---------- */

    for (int i = 0; i < sched->num_tasks; i++) {
        char key[32];
        snprintf(key, sizeof(key), "scheduletask:%d", i + 1);

        r = redisCommand(ctx, "HGETALL %s", key);
        if (!r || r->type != REDIS_REPLY_ARRAY) continue;

        task_t *task = &sched->tasks[i];

        if ((v = hget(r, "name")))
            strncpy(task->name, v, sizeof(task->name));

        if ((v = hget(r, "policy")))
            strncpy(task->policy, v, sizeof(task->policy));

        if ((v = hget(r, "priority")))
            task->priority = atoi(v);

        if ((v = hget(r, "inputs")))
            strncpy(task->inputs, v, sizeof(task->inputs));

        if ((v = hget(r, "outputs")))
            strncpy(task->outputs, v, sizeof(task->outputs));

        freeReplyObject(r);
    }

    return 0;
}

--- END FILE: services/execution-manager/src/redis_reader.c ---

--- START FILE: services/execution-manager/src/main.c ---
#include <stdio.h>
#include <unistd.h>
#include "redis_reader.h"
#include "task_ipc.h"

int main(void)
{
    // Execution Manager init
    redisContext *ctx = redis_connect("redis", 6379);
    mqd_t em_queue = create_queue(QUEUE_NAME_EM, O_RDONLY);

    
    // Wait until there is a schedule to perform 
    redis_wait_for_schedule(ctx);

    // Read schedule
    schedule_t s;
    redis_read_schedule(ctx, &s);

    printf("\n=== SCHEDULE ===\n");
    printf("Name: %s\n", s.name);
    printf("Version: %s\n", s.version);
    printf("Tasks: %d\n", s.num_tasks);

    for (int i = 0; i < s.num_tasks; i++) {
        task_t *t = &s.tasks[i];
        printf("\nTask %d\n", i+1);
        printf("  Name     : %s\n", t->name);
        printf("  Policy   : %s\n", t->policy);
        printf("  Priority : %d\n", t->priority);
        printf("  Inputs   : %s\n", t->inputs);
        printf("  Outputs  : %s\n", t->outputs);
    
    }


    while (1) {
        redis_read_schedule(ctx, &s);

        printf("\n=== SCHEDULE ===\n");
        printf("Name: %s\n", s.name);
        printf("Version: %s\n", s.version);
        printf("Tasks: %d\n", s.num_tasks);

        for (int i = 0; i < s.num_tasks; i++) {
            task_t *t = &s.tasks[i];
            printf("\nTask %d\n", i+1);
            printf("  Name     : %s\n", t->name);
            printf("  Policy   : %s\n", t->policy);
            printf("  Priority : %d\n", t->priority);
            printf("  Inputs   : %s\n", t->inputs);
            printf("  Outputs  : %s\n", t->outputs);
        }

        sleep(1);
    }
}

--- END FILE: services/execution-manager/src/main.c ---

--- START FILE: services/task-service/CMakeLists.txt ---
cmake_minimum_required(VERSION 3.20)
project(task_service C)

set(CMAKE_C_STANDARD 99)
set(CMAKE_C_STANDARD_REQUIRED ON)
set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -Wall -Wextra -O2")

# Include directories
include_directories(${CMAKE_CURRENT_SOURCE_DIR}/include)

# Add executable
add_executable(task-service
    src/main.c
    src/logger.c  # directly add logger.c to build
    src/task_ipc.c
)

# Threads
find_package(Threads REQUIRED)
target_link_libraries(task-service PRIVATE Threads::Threads)


# Default queue prefix if not passed
if(NOT DEFINED TASK_QUEUE_PREFIX)
    set(TASK_QUEUE_PREFIX "/task")
endif()

# Generate header from template
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/include/task_config.h.in
    ${CMAKE_CURRENT_BINARY_DIR}/task_config.h
    @ONLY
)

# Include generated header
include_directories(${CMAKE_CURRENT_BINARY_DIR})

--- END FILE: services/task-service/CMakeLists.txt ---

--- START FILE: services/task-service/Dockerfile ---
FROM ubuntu:24.04

# Docker build argument
ARG TASK_QUEUE_PREFIX="/task"

# Install build tools
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        build-essential \
        cmake  &&\
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy task-service source
COPY . ./task-service/

WORKDIR /app/task-service

# Configure and build
RUN cmake -S . -B build -DTASK_QUEUE_PREFIX=${TASK_QUEUE_PREFIX}
RUN cmake --build build

ENTRYPOINT ["./build/task-service"]

--- END FILE: services/task-service/Dockerfile ---

--- START FILE: services/task-service/include/task_config.h.in ---
#pragma once

// Queue prefix injected at build time
#define TASK_QUEUE "@TASK_QUEUE_PREFIX@"

--- END FILE: services/task-service/include/task_config.h.in ---

--- START FILE: services/task-service/include/task_service.h ---
#ifndef TASK_SERVICE_H
#define TASK_SERVICE_H

#include <stdint.h>
#include <pthread.h>

/* Possible states */
typedef enum { IDLE, RUNNING, COMPLETED, FAULT } task_state_t;

/* Task descriptor */
typedef struct {
    pthread_t thread;
    pthread_attr_t attr;
    task_state_t state;
    int priority;
} task_service_t;


#endif /* TASK_SERVICE_H */

--- END FILE: services/task-service/include/task_service.h ---

--- START FILE: services/task-service/include/task_entry.h ---

--- END FILE: services/task-service/include/task_entry.h ---

--- START FILE: services/task-service/src/main.c ---
#include <stdio.h>
#include "task_entry.h"

#include "task_config.h"
#include <stdint.h>

char queue_name[64];

void get_task_queue_name(uint32_t task_id) {
    snprintf(queue_name, sizeof(queue_name), "%s", TASK_QUEUE);
}

int main() {
    get_task_queue_name(1);
    printf("Queue name: %s\n", queue_name);
    return 0;
}


/********* 
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <pthread.h>
#include "task_ipc.h"

mqd_t em_queue, task_queue;


void* run_task(void* arg) {
    task_t *task = (task_t*)arg;

    printf("[Task Service] Running task '%s' with priority %u\n", task->task_name, task->priority);
    // Simulate computation
    sleep(1);

    // Send ACK
    ipc_msg_t ack;
    ack.type = MSG_TASK_ACK;
    ack.task_id = 0; // could use task ID
    ack.status = ACK_OK;
    snprintf(ack.payload, MAX_MSG_SIZE, "Task '%s' completed successfully", task->task_name);

    send_message(em_queue, &ack);

    free(task);
    return NULL;
}

int main() {
    em_queue   = create_queue(QUEUE_NAME_EM);
    task_queue = create_queue(QUEUE_NAME_TASK);

    printf("[Task Service] Waiting for messages...\n");

    while (1) {
        ipc_msg_t msg;
        receive_message(task_queue, &msg);

        switch (msg.type) {
            case MSG_TASK_REQUEST: {
                task_t *task = malloc(sizeof(task_t));
                memcpy(task, msg.payload, sizeof(task_t));

                pthread_t thread;
                pthread_create(&thread, NULL, run_task, task);
                pthread_detach(thread);
                break;
            }

            case MSG_GET_STATUS: {
                ipc_msg_t status_msg;
                status_msg.type    = MSG_TASK_STATUS;
                status_msg.task_id = msg.task_id;
                status_msg.status  = ACK_OK;
                snprintf(status_msg.payload, MAX_MSG_SIZE, "Task %u status: running", msg.task_id);
                send_message(em_queue, &status_msg);
                break;
            }

            case MSG_GET_RESULTS: {
                ipc_msg_t result_msg;
                result_msg.type    = MSG_TASK_RESULT;
                result_msg.task_id = msg.task_id;
                result_msg.status  = ACK_OK;
                snprintf(result_msg.payload, MAX_MSG_SIZE, "{\"result\": 42}");
                send_message(em_queue, &result_msg);
                break;
            }

            default:
                printf("[Task Service] Unknown message type %d\n", msg.type);
        }
    }

    close_queue(em_queue, QUEUE_NAME_EM);
    close_queue(task_queue, QUEUE_NAME_TASK);
    return 0;
}

***************/

/* 
#include <stdio.h>
#include <string.h>

#include "task.h"
#include "logger.h"

int main(void) {
    task_t task;

    
    strncpy(task.task_name, "test_task", TASK_NAME_MAX);
    task.policy = SCHED_POLICY_FIFO;
    task.priority = 50;

    strncpy(task.input, "{\"a\": 3, \"b\": 4}", TASK_JSON_IN_MAX);
    strncpy(task.output, "{\"sum\": 7, \"product\": 12}", TASK_JSON_OUT_MAX);

    
    printf("Task name   : %s\n", task.task_name);
    printf("Policy      : %d\n", task.policy);
    printf("Priority    : %u\n", task.priority);
    printf("Input JSON  : %s\n", task.input);
    printf("Output JSON : %s\n", task.output);

    l 
    log_message(LOG_WARN, "task_service", "Task execution delayed!");
    log_message(LOG_ERROR, "rt_task", "Thread creation failed with code %d", -1);

    return 0;
}

  */
--- END FILE: services/task-service/src/main.c ---

--- START FILE: services/deploy-manager/Dockerfile ---
# Single-stage Dockerfile for deploy-manager

FROM python:3.14-slim

# Environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Working directory
WORKDIR /app

# Runtime dependencies (Git needed by GitPython)
RUN apt-get update && \
    apt-get install -y --no-install-recommends git && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Copy source code
COPY services/deploy-manager/pyproject.toml .
COPY services/deploy-manager/src/ ./src/
COPY services/task-service/ ./task-service/
COPY common/include/ task-service/include/
COPY common/src/ task-service/src/


# Install deploy-manager and its dependencies
RUN pip install --no-cache-dir .

# Entrypoint
ENTRYPOINT ["python", "-m", "src.main"]
--- END FILE: services/deploy-manager/Dockerfile ---

--- START FILE: services/deploy-manager/pyproject.toml ---
[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "deploy-manager"
version = "0.0.0" 
description = "Deploy Manager for Real-Time Microservices"
requires-python = "==3.14.*"

dependencies = [
    "GitPython==3.1.46",
    "PyYAML==6.0.3",
    "docker==7.1.0",
    "redis==7.1.0",
]

[tool.setuptools.packages.find]
where = ["src"]

--- END FILE: services/deploy-manager/pyproject.toml ---

--- START FILE: services/deploy-manager/src/__init__.py ---
# deploy_manager/__init__.py
__author__ = "Georgi Dimitrov"

--- END FILE: services/deploy-manager/src/__init__.py ---

--- START FILE: services/deploy-manager/src/logger.py ---

import logging
import sys

def get_logger(name="deploy-manager"):
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler(sys.stdout)
        formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s: %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger

--- END FILE: services/deploy-manager/src/logger.py ---

--- START FILE: services/deploy-manager/src/exceptions.py ---

class DeployManagerError(Exception):
    """Base exception for Deploy Manager errors."""
    pass

--- END FILE: services/deploy-manager/src/exceptions.py ---

--- START FILE: services/deploy-manager/src/main.py ---
from pathlib import Path
from .logger import get_logger
from .manifest.manifest_fetcher import ManifestFetcher
from .manifest.parser import ManifestParser
from .deploy.materializer import TaskArtifactMaterializer
from .deploy.builder import DockerImageBuilder
from .deploy.runner import DockerContainerRunner
from .database.redis_loader import RedisLoader  # NEW
from .exceptions import DeployManagerError
import sys

logger = get_logger(__name__)

def main():
    repo_url = "https://github.com/GeoDimi99/RT-Task-Spec.git"
    mission_path = Path("/tmp/rt-mission-spec")

    task_service_path = Path("/app/task-service")
    task_service_include = task_service_path / "include"

    fetcher = ManifestFetcher(repo_url, mission_path)
    docker_builder = DockerImageBuilder()
    docker_runner = DockerContainerRunner()
    redis_loader = RedisLoader(host="redis", port=6379)  # NEW

    try:
        # Fetch mission repository
        fetcher.fetch()

        # Parse manifest
        parser = ManifestParser(str(mission_path / "task_manifest.yaml"))
        schedule = parser.parse()

        # Materialize task entries
        materializer = TaskArtifactMaterializer(
            mission_repo_path=mission_path,
            task_service_include_path=task_service_include,
        )

        # Build and run containers for each task
        for task in schedule.tasks:
            logger.info(f"Processing task '{task.name}'")

            # Materialize task header
            materializer.materialize_task(task)

            # Build Docker image
            image_tag = f"task-service:{task.name}-{schedule.version}"
            docker_builder.build_task_service_image(
                build_context=task_service_path,
                image_tag=image_tag,
                task_queue_prefix="/" + task.name
            )

            # Run container
            container_name = f"task-service-{task.name}"
            docker_runner.run_task_service(
                image_tag=image_tag,
                container_name=container_name,
            )
        
        # Load schedule and tasks into Redis
        redis_loader.load_schedule(schedule)
        redis_loader.debug_print()  # REMOVE AFTER DEBUGGING
        logger.info("Schedule data loaded into Redis successfully.")
        

    except DeployManagerError as e:
        logger.error(f"Deploy Manager failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

--- END FILE: services/deploy-manager/src/main.py ---

--- START FILE: services/deploy-manager/src/database/__init__.py ---

--- END FILE: services/deploy-manager/src/database/__init__.py ---

--- START FILE: services/deploy-manager/src/database/redis_loader.py ---
# src/deploy/redis_loader.py
import redis
import json
from ..logger import get_logger
from ..domain.schedule import Schedule

logger = get_logger(__name__)

class RedisLoader:
    """
    Loads schedule/task data into Redis for debugging purposes.
    """

    def __init__(self, host="localhost", port=6379, db=0):
        self.client = redis.Redis(host=host, port=port, db=db, decode_responses=True)

    def load_schedule(self, schedule: Schedule):
        """
        Push schedule and tasks into Redis.
        """
        self.client.hset("schedule", mapping={
            "name": schedule.name,
            "version": schedule.version,
            "description": schedule.description,
            "length": str(len(schedule.tasks))
        })

        for i, task in enumerate(schedule.tasks, start=1):
            task_key = f"scheduletask:{i}"
            self.client.hset(task_key, mapping={
                "name": task.name,
                "policy": task.policy,
                "priority": str(task.priority),
                "depends_on": json.dumps(task.depends_on),
                "inputs": json.dumps(task.inputs),
                "outputs": json.dumps(task.outputs),
            })


        logger.info(f"Loaded {len(schedule.tasks)} tasks into Redis.")

    def debug_print(self):
        """
        Read back all schedule/task data and print for debugging.
        """
        schedule_data = self.client.hgetall("schedule")
        print("=== SCHEDULE ===")
        for k, v in schedule_data.items():
            print(f"{k}: {v}")

        print("\n=== TASKS ===")
        length = int(schedule_data.get("length", 0))
        for i in range(1, length + 1):
            task_key = f"scheduletask:{i}"
            task_data = self.client.hgetall(task_key)
            print(f"{task_key}: {task_data}")

--- END FILE: services/deploy-manager/src/database/redis_loader.py ---

--- START FILE: services/deploy-manager/src/deploy/runner.py ---
import docker
from ..logger import get_logger
from ..exceptions import DeployManagerError

logger = get_logger(__name__)

class DockerContainerRunner:
    """
    Runs Docker containers for task services with the required real-time privileges.
    """

    def __init__(self):
        self.client = docker.from_env()

    def run_task_service(
        self,
        image_tag: str,
        container_name: str = "task-service",
        detach: bool = True,
    ):
        """
        Run a task-service container with privileged capabilities and ulimits.
        """

        try:
            # Remove existing container if it exists
            try:
                existing = self.client.containers.get(container_name)
                logger.info(f"Stopping and removing existing container '{container_name}'")
                existing.stop()
                existing.remove()
            except docker.errors.NotFound:
                pass  # Container does not exist, OK

            logger.info(f"Running container '{container_name}' from image '{image_tag}'")

            container = self.client.containers.run(
                image=image_tag,
                name=container_name,
                detach=detach,
                tty=True,
                ipc_mode="host",
                cap_add=["SYS_NICE"],
                ulimits=[
                    docker.types.Ulimit(name="rtprio", soft=99, hard=99),
                    docker.types.Ulimit(name="memlock", soft=-1, hard=-1),
                ],
                cpuset_cpus="1",
                #remove=True,
            )

            logger.info(f"Container '{container_name}' is running (ID: {container.short_id})")
            return container

        except docker.errors.DockerException as e:
            raise DeployManagerError(f"Failed to run container '{container_name}': {e}")

--- END FILE: services/deploy-manager/src/deploy/runner.py ---

--- START FILE: services/deploy-manager/src/deploy/__init__.py ---

--- END FILE: services/deploy-manager/src/deploy/__init__.py ---

--- START FILE: services/deploy-manager/src/deploy/materializer.py ---
from pathlib import Path
import shutil
from ..logger import get_logger
from ..exceptions import DeployManagerError
from ..domain.task import Task

logger = get_logger(__name__)

class TaskArtifactMaterializer:
    """
    Materializes task-specific artifacts into the task-service build context.
    """

    def __init__(
        self,
        mission_repo_path: Path,
        task_service_include_path: Path,
    ):
        self.mission_repo_path = mission_repo_path
        self.task_service_include_path = task_service_include_path

    def materialize_task(self, task: Task) -> None:
        """
        Copy task_entry.h for a given task into task-service/include/
        """
        source_header = (
            self.mission_repo_path
            / task.name
            / "task_entry.h"
        )

        if not source_header.exists():
            raise DeployManagerError(
                f"task_entry.h not found for task '{task.name}' "
                f"at {source_header}"
            )

        destination = self.task_service_include_path / "task_entry.h"

        try:
            shutil.copyfile(source_header, destination)
            logger.info(
                f"Injected task '{task.name}' entry header into task-service"
            )
        except Exception as e:
            raise DeployManagerError(
                f"Failed to materialize task '{task.name}': {e}"
            )

--- END FILE: services/deploy-manager/src/deploy/materializer.py ---

--- START FILE: services/deploy-manager/src/deploy/builder.py ---
import docker
from pathlib import Path
from ..logger import get_logger
from ..exceptions import DeployManagerError

logger = get_logger(__name__)

class DockerImageBuilder:
    """
    Builds Docker images for task services.
    """

    def __init__(self):
        self.client = docker.from_env()

    def build_task_service_image(
        self,
        build_context: Path,
        image_tag: str,
        task_queue_prefix: str = "/task"
    ) -> None:
        try:
            logger.info(
                f"Building Docker image '{image_tag}' "
                f"from {build_context}"
            )
            image, logs = self.client.images.build(
                path=str(build_context),
                tag=image_tag,
                rm=True,
                buildargs={"TASK_QUEUE_PREFIX": task_queue_prefix}
            )
            logger.info(f"Successfully built image '{image_tag}'")
        except docker.errors.BuildError as e:
            raise DeployManagerError(f"Docker build failed: {e}")
        except Exception as e:
            raise DeployManagerError(f"Docker error: {e}")

--- END FILE: services/deploy-manager/src/deploy/builder.py ---

--- START FILE: services/deploy-manager/src/manifest/manifest_fetcher.py ---
# src/manifest/manifest_fetcher.py
from pathlib import Path
from git import Repo, GitCommandError
from ..logger import get_logger
from ..exceptions import DeployManagerError

logger = get_logger(__name__)

class ManifestFetcher:

    def __init__(self, url: str, local_path: Path):
        self.url = url
        self.local_path = local_path

    def fetch(self) -> None:
        """
        Clone the repository if it doesn't exist, otherwise pull the latest changes.
        """
        try:
            if self.local_path.exists():
                logger.info(f"Repository exists at {self.local_path}, pulling latest changes...")
                repo = Repo(self.local_path)
                origin = repo.remotes.origin
                origin.pull()
                logger.info("Repository updated successfully.")
            else:
                logger.info(f"Cloning repository from {self.url} to {self.local_path}...")
                Repo.clone_from(self.url, self.local_path)
                logger.info("Repository cloned successfully.")

        except GitCommandError as e:
            raise DeployManagerError(f"Git error: {e}")

--- END FILE: services/deploy-manager/src/manifest/manifest_fetcher.py ---

--- START FILE: services/deploy-manager/src/manifest/__init__.py ---

--- END FILE: services/deploy-manager/src/manifest/__init__.py ---

--- START FILE: services/deploy-manager/src/manifest/parser.py ---
# src/manifest/parser.py
from typing import List
import yaml
from ..exceptions import DeployManagerError
from ..logger import get_logger
from ..domain.task import Task
from ..domain.schedule import Schedule

logger = get_logger(__name__)

class ManifestParser:
    # Only fifo and rr for now
    VALID_POLICIES = {"fifo", "rr"}

    def __init__(self, manifest_path: str):
        self.manifest_path = manifest_path

    def parse(self) -> Schedule:
        """
        Parse a YAML manifest file and return a Schedule object composed of Task objects.
        """
        try:
            with open(self.manifest_path, "r") as f:
                data = yaml.safe_load(f)
        except FileNotFoundError:
            raise DeployManagerError(f"Manifest file not found: {self.manifest_path}")
        except yaml.YAMLError as e:
            raise DeployManagerError(f"Error parsing YAML manifest: {e}")

        # Validate top-level fields
        if "schedule" not in data:
            raise DeployManagerError("Manifest missing required field: 'schedule'")

        schedule_data = data["schedule"]
        tasks_data = schedule_data.get("tasks", [])

        # Parse tasks into domain Task objects
        tasks: List[Task] = []
        for t in tasks_data:
            try:
                task = Task(
                    name=t["name"],
                    policy=t["policy"].lower(),
                    priority=int(t["priority"]),
                    depends_on=t.get("depends_on", []),
                    inputs=t.get("inputs", {}),
                    outputs=t.get("outputs", {}),
                )
            except KeyError as e:
                raise DeployManagerError(f"Task missing required field: {e}")

            # Validate policy
            if task.policy not in self.VALID_POLICIES:
                raise DeployManagerError(f"Invalid policy '{task.policy}' in task {task.id}")

            tasks.append(task)

        # Build Schedule domain object
        schedule = Schedule(
            name=schedule_data.get("name", "unnamed"),
            version=schedule_data.get("version", "0.0.0"),
            description=schedule_data.get("description", ""),
            tasks=tasks
        )

        logger.info(f"Parsed schedule '{schedule.name}' with {len(tasks)} tasks.")
        return schedule

--- END FILE: services/deploy-manager/src/manifest/parser.py ---

--- START FILE: services/deploy-manager/src/domain/task.py ---
# domain/task.py
from dataclasses import dataclass, field
from typing import Dict, List, Any

@dataclass
class Task:
    name: str
    policy: str
    priority: int
    depends_on: List[str] = field(default_factory=list)
    inputs: Dict[str, Any] = field(default_factory=dict)
    outputs: Dict[str, Any] = field(default_factory=dict)

--- END FILE: services/deploy-manager/src/domain/task.py ---

--- START FILE: services/deploy-manager/src/domain/__init__.py ---

--- END FILE: services/deploy-manager/src/domain/__init__.py ---

--- START FILE: services/deploy-manager/src/domain/schedule.py ---
# src/domain/schedule.py
from dataclasses import dataclass
from typing import List
from .task import Task  # import from domain

@dataclass
class Schedule:
    name: str
    version: str
    description: str
    tasks: List[Task]

--- END FILE: services/deploy-manager/src/domain/schedule.py ---
